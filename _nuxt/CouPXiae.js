const e={websiteTitle:"In-Memory and In-storage Processing",pitch:"International Online Workshop on",title:"In-Memory and In-Storage Processing",subTitle:"September 25-26, 2025"},i="In-memory/storage processing (IMP/ISP) refers to the capability of performing computations directly within the memory/storage subsystem, rather than relying solely on traditional processing units. This paradigm shift addresses the growing challenges of data deluge and the limitations of conventional architectures, enabling faster data access, reduced latency, and improved energy efficiency.<br><br>As the volume of data generated continues to grow exponentially, traditional architectures face significant hurdles in managing and processing this data efficiently. IMP/ISP offers a solution by bringing computation closer to the data, thereby minimizing the data movement between processing and memory/storage subsystem. This innovation not only enhances performance but also reduces the energy consumption associated with data transfer, making it a more sustainable choice for future supercomputing and data centers. By leveraging advancements in memory technologies, such as non-volatile memory (NVM) and emerging storage architectures, IMP/ISP opens new avenues for optimizing big data analytics, machine learning, and real-time data processing.<br><br>The International Online Workshop on Recent Advances in Processing-in-Memory/Storage brings together researchers, practitioners, and industry leaders from around the globe to explore the transformative potential of IMP/ISP technologies. This workshop aims to foster collaboration and innovation in a field that is reshaping the future of high-performance computing, and data management and analytics.<br><br>Throughout this workshop, participants will have the opportunity to engage with a diverse range of topics, including but not limited to:<br>• Architectural Innovations: Discover the latest developments IMP/ISP architectures that and their implications for system design.<br>• Performance Optimization: Learn about techniques to optimize data processing workloads in memory/storage subsystems, enhancing overall system performance.<br>• Applications and Case Studies: Explore real-world applications and case studies demonstrating the effectiveness of IMP/ISP in various domains and scientific research.<br>• Challenges and Future Directions: Engage in discussions about the current challenges facing the field and potential future directions for research and development.<br><br>The workshop will feature talks from renowned researchers from all over the world. Together, participants can explore the frontiers of IMP/ISP and its potential to revolutionize how we handle and analyze data in an increasingly data-driven world.<br><br>This workshop aims to bring together leading researchers, engineers, and graduate students in the field of IMP/ISP, and encourage active participation, knowledge sharing, and networking among attendees.<br><br>The International Online Workshop on Recent Advances in Processing-in-Memory/Storage is jointly supported by the Korean Institute of Information Scientists and Engineers (KIISE), and the Computer Society of Iran (CSI).",n=[{profile:"./images/Kevin_Skadron.jpeg",name:"Kevin Skadron",rank:"Professor",description:"",email:" ks7h@virginia.edu",linkedin:""},{profile:"./images/sudeep-pasricha.jpg",name:"Sudeep Pasricha",rank:"Professor",description:"",email:"sudeep@colostate.edu",linkedin:""},{profile:"./images/Oguz_Ergin.jpeg",name:"Oguz Ergin",rank:"Professor",description:"",email:"oergin@sharjah.ac.ae",linkedin:""},{profile:"./images/Xueqing_Li.jpeg",name:"Xueqing Li",rank:"Associate Professor",description:"",email:"xueqingli@tsinghua.edu.cn",linkedin:""},{profile:"./images/Mehdi_Modarressi.jpeg",name:"Mehdi Modarressi",rank:"Associate Professor",description:"",email:"modarressi@ut.ac.ir",linkedin:""},{profile:"./images/Ahmad_Patooghy.jpeg",name:"Ahmad Patooghy",rank:"Associate Professor",description:"",email:"apatooghy@ncat.edu",linkedin:""},{profile:"./images/Elaheh_Sadredini.jpeg",name:"Elaheh Sadredini",rank:"Assistant Professor",description:"",email:"elaheh@cs.ucr.edu",linkedin:""},{profile:"./images/hamed_farbeh.jpeg",name:"Hamed Farbeh",rank:"Assistant professor",description:"",email:"test@example.com",linkedin:""},{profile:"./images/Esteban_Garzon.jpg",name:"Esteban Garzon",rank:"Assistant Professor",description:"",email:"esteban.garzon@unical.it",linkedin:""},{profile:"./images/khilesh_Jaiswal.jpeg",name:"Akhilesh Jaiswal",rank:"Assistant Professor",description:"",email:"akhilesh.jaiswal@wisc.edu",linkedin:""},{profile:"./images/mohammad_sadrosadati.jpeg",name:"Mohammad Sadrossadati",rank:"Senior Researcher",description:"",email:"mohammad.sadrosadati@safari.ethz.ch",linkedin:""},{profile:"./images/nazem_rohbani.jpeg",name:"Nezam Rohbani",rank:"Researcher",description:"",email:"rohbani@ipm.ir",linkedin:""}],a=JSON.parse(`[{"title":"Day 1, Thursday, 25 September 2025 <strong>(South Korea time)</strong>","date":"","timeTable":[{"time":"13:00 ~ 13:10","speaker":"Jeong-A Lee","topic":"Opening Remarks","content":"Welcome and introduction to the workshop.","link":"","bio":""},{"time":"13:10 ~ 14:00","speaker":"Kevin Skadron","topic":"Processing in Memory: Design Tradeoffs to Boost Data Access Bandwidth","content":"Applications are increasingly data-intensive and bound by the performance of the memory system. This “memory wall” makes processing in or near memory (PIM/PNM) appealing, but even with processing units directly attached to memory, the limited bandwidth of the bank and channel interfaces limits benefits. This talk will explore the design tradeoffs and application characteristics that optimize PIM/PNM performance, and explore DRAM changes that enable higher throughput and allow PIM/PNM to provide benefits at higher operational intensities.","link":"","bio":"Kevin Skadron is the Harry Douglas Forsyth Professor of Computer Science at the University of Virginia, where he has been on the faculty since 1999, after receiving his PhD at Princeton in 1999. He served as department chair from 2012-2021. He is a Fellow of the IEEE and the ACM, and a recipient of the 2011 ACM SIGARCH Maurice Wilkes Award and the 2023 SRC-SIA University Research Award. Skadron's research interests include design and application of accelerators and heterogeneous architectures, their memory hierarchies, and associated power, thermal, reliability, and programming challenges. He and his colleagues and students have developed a number of tools to support research on these topics, such as AutomataZoo, HotSpot, Rodinia, and PIMeval/PIMbench, and the PIM programming API.","slide_link":""},{"time":"14:00 ~ 14:50","speaker":"Akhilesh Jaiswal","topic":"A Photonic SRAM Pathway to Ultrafast, Scalable, Robust Analog Compute-in-Memory","content":"The exponential rise in data from IoT, AI, and ML applications necessitates ultra-fast, scalable, and energy-efficient hardware solutions. Traditional von Neumann architectures struggle with latency and power inefficiencies due to memory-processor bottlenecks. While electrical memory technologies featuring in-memory computing have been extensively explored to mitigate the memory-processor bottleneck, they face increasing speed and throughput limitations from bitline capacitances, wordline resistances, and interconnect scaling. In contrast, photonics-based in-memory computing offers transformative speed and energy advantages, leveraging ultra-fast operating frequencies, low crosstalk, and high data bandwidth. In this talk I will present a novel differential photonic SRAM (pSRAM) bitcell-augmented mixed-signal photonic tensor core, designed for high-speed and energy-efficient analog matrix multiplication. Additionally, I will introduce a novel 1-hot encoding electro-optic analog-to-digital converter (eoADC), enabling seamless transition from photonic computation to electrical-domain processing. Together the photonic SRAM bit-cell, embedded analog-in-memory computing ability and the novel eoADC sets up the groundwork needed to create scalable, ultra-fast photonic solutions for various datacenter and computing applications.","link":"","bio":"Dr. Akhilesh Jaiswal is an Assistant Professor of Electrical and Computer Engineering at the University of Wisconsin-Madison. His wider research interests include device-circuit co-design using existing and alternate state variables for future computing systems. Dr. Jaiswal has authored some of the initial works on Processing-in-Pixel and SRAM based in-memory computing. He is recipient of ISI Exploratory Research Award in 2020, Keston Exploratory Research Award in 2021, IEEE Brain Community Best Paper Award in 2022, and Best Paper Nomination in VLSI-SoC 2022. He has authored several articles in leading peer-reviewed journals and conferences and has over 45 issued/pending patents.","slide_link":""},{"time":"14:50 ~ 15:40","speaker":"Nezam Rohbani","topic":"Leveraging DRAM’s Intrinsic Features for In-Memory Processing","content":"In-memory processing has emerged as a promising paradigm to overcome the memory bottleneck in modern computing systems by reducing data movement between memory and processors. DRAM, as the dominant main memory technology, offers unique architectural and physical features that can be exploited to perform computation within the memory itself. In this talk, we explore how specific characteristics of DRAM—such as differential cell access using paired bitlines, the structure and behavior of sense amplifiers, and the inherent dynamic nature of charge leakage in DRAM cells—can be leveraged to enable efficient bitwise operations directly inside DRAM arrays. We highlight the fundamental challenges of implementing logic operations in commodity DRAM devices and present some of our previous works that demonstrate innovative techniques for in-DRAM computation. These approaches show the potential of DRAM not only as a storage medium but also as an active computational substrate, paving the way for more energy-efficient and data-centric computing architectures.","link":"","bio":"Nezam Rohbani received his Ph.D. from Sharif University of Technology in Tehran, Iran. He later worked as a postdoctoral researcher at the Institute for Research in Fundamental Sciences (IPM) for five years. He is currently a Senior Research Engineer at the Barcelona Supercomputing Center (BSC), where his research focuses on in-memory processing, AI accelerators, and the design of low-power, reliable DRAM systems for next-generation computing. He has authored multiple publications in high-ranked conferences in the fields of computer architecture and memory systems.","slide_link":""},{"time":"15:40 ~ 16:00","speaker":"","topic":"Break","content":"","link":"","bio":""},{"time":"16:00 ~ 16:50","speaker":"Hamed Farbeh","topic":"Investigating Fault Vulnerabilities in ReRAM-Based PIM Accelerators for Deep CNNs","content":"Resistive random-access memory (ReRAM)-based processing-in-memory (PIM) accelerators enable parallel execution of memory-intensive matrix-vector multiplications in neural networks, leveraging analog computation, ultra-high density, minimal leakage current, and nonvolatility. Despite these advantages, fabrication-induced process variations and defects compromise reliability, degrading the accuracy of deep convolutional neural networks (CNNs) deployed on PIM architectures. While increasingly integrated into safety-critical applications, the fault susceptibility of CNN accelerators remains insufficiently explored. We analyze CNN vulnerability at software and hardware inference phases, investigating the impact of stuck-at-high (SaH) and stuck-at-low (SaL) faults in ReRAM across diverse layer depths, parameter locations, and fault characteristics. Our study demonstrates that fault-induced performance degradation is highly dependent on the architecture, parameter positioning, and fault type. Notably, model-specific fault sensitivities emerge, with SaL faults inflicting greater accuracy loss than SaH. These findings underscore the necessity for tailored resilience mechanisms to enhance reliability in ReRAM-based PIM accelerators, contributing to robust AI processing in error-prone memory environments.","link":"","bio":"Hamed Farbeh received his B.Sc., M.Sc., and PhD degrees in Computer Engineering from Sharif University of Technology (SUT), Tehran, Iran, in 2009, 2011, and 2017, respectively. He was a member of the Dependable Systems Laboratory (DSL) at SUT from 2007 to 2017. He also served as a Visiting Researcher at the Embedded Computing Laboratory (ECL), KAIST, Daejeon, South Korea, from October 2014 to May 2015, and collaborated as a Postdoctoral Fellow with the Institute for Research in Fundamental Sciences (IPM), Tehran, Iran, from May 2017 to January 2018. Additionally, he visited the Faculty of Computer Science and Mathematics at Passau University during the summers of 2022 and 2024. He received the Best Paper Award at the IEEE/ACM Design, Automation, and Test in Europe (DATE) conference in 2019, as well as multiple awards from Iran’s National Elites Foundation. He also served as the official delegate of Iran at the 9th BRICS Young Scientist Forum in Sochi. He is currently a faculty member of the Department of Computer Engineering at Amirkabir University of Technology (Tehran Polytechnic-AUT), Tehran, Iran, where he founded the Intelligent Computing and Communication Infrastructure Laboratory (ICCI). From October 2020 to December 2024, he served as director of the Computer Systems Architecture and Networks (CSAN) group at AUT. Since February 2018, he has also been a board member of the Cyber-Physical Systems Society of Iran (CPSSI). His research interests include emerging memory technologies, AI processors, Internet-of-things, and cyber-physical systems.","slide_link":""},{"time":"16:50 ~ 17:40","speaker":"Xueqing Li","topic":"Ultra-high-density CMOS compute-in-memory circuits and architectures","content":"Compute-in-Memory (CiM) has been recognized as a promising enabler for achieving energy-efficient artificial intelligence (AI) acceleration. However, existing CiM implementations based on mature CMOS processes, such as SRAM and eDRAM, face significant limitations in storage density, necessitating frequent off-chip DRAM accesses for weight data retrieval in data-intensive applications. This constraint severely compromises task-level energy efficiency. This talk introduces a hybrid SRAM-ROM multiply-accumulate (MAC) CiM macro architecture, demonstrating convolutional neural network (CNN) and Transformer acceleration chips with Marco-level memory density of 4Mb/mm^2 in 65nm CMOS, 9Mb/mm^2 in 28nm CMOS, and 20Mb/mm^2 in 28nm CMOS. The design supports flexible task expansion through transfer learning, YOLOC (an optimized YOLO framework for CiM), and Hidden-ROM (a memory-hiding technique for privacy-preserving inference).","link":"","bio":"Dr. Xueqing Li is currently an Associate Professor at the Department of Electronic Engineering, Tsinghua University, Beijing, China. Between 2013 and 2017, he was a posdoc at Penn State University. His research interests include mixed-signal circuits, emerging memory and memory-oriented computing circuits and architecture. Dr. Li has published 170+ papers, including 17 in JSSC and ISSCC. Dr. Li received a few best paper awards, National Early-Career Award, and other research, teaching and thesis awards. Dr. Li also served as Associate/Guest Editor in a few IEEE journals (JSSC, TVLSI, TETC, JETCAS, etc.), and TPC in a few conferences (ISSCC, DAC, ICCAD, DATE, etc.)","slide_link":""},{"time":"17:40 ~ 18:30","speaker":"Esteban Garzon","topic":"In-Memory Processing-Based Hardware Accelerators for Transformer Architectures","content":"Transformer-based neural networks have revolutionized artificial intelligence (AI), driving innovation across business, robotics, transportation, education, and numerous other sectors. At their core, these models rely on self-attention mechanisms with quadratic computational complexity, requiring extensive matrix-vector operations that demand substantial computing resources. Large language models exemplify these challenges, necessitating trillions of operations and enormous datasets that generate significant carbon footprints, and limited their deployment for AI at the edge. As models continue to grow in size and complexity, they increasingly strain data center infrastructures and exacerbate the “memory wall” problem, a fundamental limitation in traditional von Neumann architectures where memory bandwidth and access speed constraints create bottlenecks, while simultaneously consuming vast amounts of energy during data transfer. This talk presents innovative circuit and computer architecture solutions to these computational barriers. It focuses on In-Memory Processing (IMP) architectures as a promising alternative to conventional computing approaches. By integrating computation directly within memory units, IMP-based hardware solutions offer dramatic improvements in energy efficiency and sustainability for AI systems.","link":"","bio":"Esteban Garzón received the Ph.D. degree (Hons.) in electronics engineering from the University of Calabria (UNICAL), Italy, in 2022. He is currently an assistant professor at the Department of Computer Engineering, Modeling, Electronics, and Systems Engineering, UNICAL, Italy. He has authored/co-authored more than 55 scientific papers in international peer-reviewed journals and conferences and has participated in several IC tapeouts. He has received several awards, research grants, and funding. His research interests include domain-specific hardware accelerators, Spintronics, embedded memories, and standard and emerging technologies for logic and memory, and low-power applications. He is an IEEE Senior Member, and has been part of several IEEE conference committees and journal boards.","slide_link":""}]},{"title":"Day 2, Friday, 26 September 2025 <strong>(South Korea time)</strong>","date":"","timeTable":[{"time":"13:10 ~ 14:00","speaker":"Sudeep Pasricha","topic":"A New Approach for Neural Network Acceleration with In-Memory Photonic Computing","content":"Recent advances in machine learning (ML) have highlighted the pressing need for computing architectures that bridge the gap between memory bandwidth and processing power. The advent of deep neural networks has pushed traditional Von Neumann architectures to their limits due to the high latency and energy consumption costs associated with data movement between the processor and memory for these workloads. One of the solutions to overcome this bottleneck is to perform computation within the main memory through processing-in-memory (PIM), thereby limiting data movement and the costs associated with it. However, DRAM-based PIM struggles to achieve high throughput and energy efficiency due to internal data movement bottlenecks and the need for frequent refresh operations. In this talk, I will introduce a novel approach that utilizes computing within photonic main memory to accelerate ML workloads. This approach has been designed to leverage the inherent massive parallelism of photonics while supporting high-speed, low-energy computation within the photonic main memory substrate. A comprehensive analysis of the proposed photonic PIM accelerator will be presented, to help guide design choices and operational mechanisms. Additionally, experimental analysis shows that the photonic PIM architecture can achieve 2.98x higher throughput and 137x better energy efficiency than the best-known prior work.","link":"","bio":"Sudeep Pasricha is the Aram and Helga Budak Endowed Professor in the Department of Electrical and Computer Engineering, the Department of Computer Science, and the Department of Systems Engineering at Colorado State University. He is Director of the Embedded, High Performance, and Intelligent Computing (EPIC) Laboratory and the Chair of Computer Engineering. He received the B.E. degree in Electronics and Communication Engineering from Delhi Institute of Technology, India, in 2000, and his Ph.D. in Computer Science from the University of California, Irvine in 2008. He joined Colorado State University (CSU) in 2008. Prior to joining CSU, he spent several years working in STMicroelectronics and Conexant Inc. His research focuses on the design and application of innovative software algorithms (particularly AI and machine learning), hardware architectures, and hardware-software co-design techniques for energy-efficient, fault-tolerant, real-time, and secure computing. He has co-authored seven books, multiple patents, and published more than 350 research articles in peer-reviewed journals and conferences, and workshops. His research has been funded by various sponsors including NSF, SRC, AFOSR, DOE, ORNL, DoD, Fiat-Chrysler, HPE, and NASA. He has served as General Chair and Program Committee Chair for multiple IEEE and ACM conferences and also served in the Editorial board of multiple IEEE and ACM journals. He has received 17 Best Paper Awards and Nominations at various IEEE and ACM conferences. Other honors and awards include: 2025 CSU Board of Governors Excellence in Graduate Teaching Award, 2025 Aram and Helga Budak Professorship, 2024 ECE Excellence in Teaching Award, 2019 George T. Abell Outstanding Research Faculty Award, the 2016-2018 University Distinguished Monfort Professorship, 2016-2019 Walter Scott Jr. College of Engineering Rockwell-Anderson Professorship, 2018 IEEE-CS/TCVLSI Mid-Career Research Achievement Award, the 2015 IEEE/TCSC Award for Excellence for a Mid-Career Researcher, the 2014 George T. Abell Outstanding Mid-Career Faculty Award, and the 2013 AFOSR Young Investigator Award. For professional service, he has received the 2019 ACM SIGDA Distinguished Service Award, the 2015 ACM SIGDA Service Award, and the 2012 ACM SIGDA Technical Leadership Award. He is a Fellow of the IEEE, Fellow of AAIA, Fellow of AIIA, Distinguished Member of the ACM, an IEEE CEDA Distinguished Lecturer, and an ACM Distinguished Speaker.","slide_link":""},{"time":"14:00 ~ 14:50","speaker":"Ahmad Patooghy","topic":"Bridging Memory-Centric AI and Real-World Edge with Heterogeneous MTJ-CMOS Compute-in-Memory Architectures","content":"As edge computing systems increasingly push the limits of performance and energy efficiency, the traditional von Neumann architecture remains a bottleneck due to its high data movement costs—often exceeding 70% of total system energy. Compute-in-Memory (CIM) architectures using Magnetic-Tunnel Junction (MTJ) technologies, such as STT-MRAM and SOT-MRAM, have emerged as a promising solution. However, widespread deployment is hindered by unresolved challenges including device variability, thermal sensitivity, memory retention versus write energy trade-offs, unreliable sense amplification, the absence of realistic benchmarks, and limited educational resources. In this talk, I discuss my efforts to integrate heterogeneous MTJ-CMOS chiplet fabrication, silicon-based calibration and error correction, and robust benchmarking under real-world Edge AI workloads. Through this platform, we aim to not only advance the scientific understanding of MTJ-based CIM but also accelerate its adoption via accessible training resources and realistic evaluation methods. This research paves the way for resilient, energy-efficient, and scalable edge AI solutions powered by next-generation memory technologies.","link":"","bio":"Ahmad Patooghy received his Ph.D. in Computer Engineering from Sharif University of Technology, Tehran, Iran, in 2011. From 2011 to 2017, he was an Assistant Professor at Iran University of Science and Technology in Tehran. In 2018, he joined the University of Central Arkansas, AR, USA. Since August 2021, he has been with the Department of Computer Systems Technology at North Carolina Agricultural and Technical State University, where he leads the Intelligent and Embedded Systems Laboratory. Dr. Patooghy has authored over 120 journal and conference papers and has served as a reviewer and program committee member for various IEEE, ACM, Elsevier, and Springer journals and conferences. He has also contributed as a panelist for the National Science Foundation, reviewing grant proposals. His research interests include security and reliability in cyber-physical systems, machine learning applications and acceleration, hardware security in IoT and Edge. Dr. Patooghy is a Senior Member of IEEE and the IEEE Computer Society and a Member of ACM.","slide_link":""},{"time":"14:50 ~ 15:40","speaker":"Elaheh Sadredini","topic":"Keep it Close, Keep it Secure! Towards Efficient, Secure, and Programmable Memory-Centric Computing","content":"Processing-in-memory (PIM) architectures are increasingly promising for accelerating data-intensive workloads, but key challenges remain in making them secure, programmable, and deployable across platforms. This talk presents our efforts to tackle these challenges through the co-design of hardware, software, and security mechanisms that make PIM systems more practical and trustworthy. We develop near-cache and in-SRAM PIM architectures that support a wide range of cryptographic kernels with high internal bandwidth and system integration. To address programmability, we develop a compiler framework that automatically maps high-level code to efficient PIM execution through advanced source transformations, PIM-aware loop optimizations, and cost-driven layout and instruction selection. To enable secure execution, we leverage secure multi-party computation (MPC) as a lightweight, privacy-preserving mechanism that enables secure computing on real-world PIM hardware. Together, these contributions bring PIM systems closer to practical deployment in both cloud and edge environments.","link":"","bio":"Elaheh Sadredini is an Assistant Professor of Computer Science and Engineering at the University of California, Riverside. Her research broadly focuses on developing secure, high-performance, and energy-efficient data-centric architectures. She received her Ph.D. from the University of Virginia in 2019 and joined UCR in 2020. Her work has appeared in top-tier venues including MICRO, ISCA, ASPLOS, and HPCA, USENIX Security, DAC, ICS, and KDD, and has earned several recognitions, including the NSF CAREER Award, a Best Paper Award at ACM Computing Frontiers, the “Best of CAL” award, and multiple best paper nominations, including HPCA’20, FCCM’20, and IISWC’19. She is also a recipient of the Hellman Fellowship and the John A. Stankovic Graduate Research Award.","slide_link":""},{"time":"15:40 ~ 16:00","speaker":"","topic":"Break","content":"","link":"","bio":""},{"time":"16:00 ~ 16:50","speaker":"Mehdi Modarressi","topic":"Network-on-memory: high bandwidth communication for PIM architectures","content":"Processing-in-Memory (PIM) is one of the most promising paradigms for addressing the bandwidth bottleneck faced by many modern data-intensive applications—perhaps most notably, deep learning (DL) workloads. However, the algorithmic and dataflow characteristics of many data-intensive applications, such as deep learning models, often require moving large volumes of data across memory banks within the device. This is necessary to bring input data and corresponding application parameters together, but it inadvertently shifts part of the bandwidth bottleneck into the memory system itself, where communication infrastructure is typically limited. In this talk, we first demonstrate that the overall throughput of a PIM-based design—particularly for DNN accelerators—is highly sensitive to both the bandwidth of inter-bank communication and the bandwidth supported by the internal PIM architecture. We then explore several approaches for facilitating efficient data movement within memory. These methods, drawn from recent advances in in-memory data transfer techniques, range from mechanisms that enable direct copying between subarrays inside the memory banks in commodity DRAM to more complex Network-on-Memory (NoM) architectures. NoM introduces a lightweight, scalable network connecting 3D-stacked memory banks, significantly boosting intra-memory data movement in terms of both concurrency and bandwidth. Finally, we show how integrating NoM into PIM-based implementations of deep learning applications can yield substantial performance improvements.","link":"","bio":"Mehdi Modarressi is an Associate Professor in the School of Electrical and Computer Engineering at the University of Tehran, Tehran, Iran. He is the founder and director of the Intelligent Architectures for Computing Systems research group. His research interests include modern memory architectures and processing-in-memory (PIM), hardware acceleration of AI models, parallel processing, and networks-on-chip (NoC).","slide_link":""},{"time":"16:50 ~ 17:40","speaker":"Oguz Ergin","topic":"In-DRAM Processing: From Infrastructure to Functionally Complete Computation","content":"Modern computing is bottlenecked by the inefficiencies of data movement between processors and memory, especially as applications grow increasingly data-intensive. Processing-in-Memory (PIM) emerges as a compelling solution by integrating computation capabilities into memory systems. This paper provides a comprehensive survey of practical developments in in-DRAM processing, emphasizing an evolutionary path from primitive data movement operations to functionally complete in-memory computation. We first review programmable DRAM characterization infrastructures such as SoftMC, DRAM-Bender, PiDRAM, and EasyDRAM, which enable fine-grained control over DRAM timing and internal behavior—laying the foundation for enabling and validating real PIM mechanisms. We then cover processing-using-memory (PUM) techniques that exploit DRAM’s internal analog and electrical properties to perform computation, beginning with primitives such as RowClone, Ambit, SALP, and LISA, and evolving into systems such as pLUTo, Buddy-RAM, SIMDRAM, MIMDRAM, Fulcrum,  DRISA,  Graphide, Proteus, and PAPI—all of which demonstrate bitwise, arithmetic, and even associative computation inside DRAM. In parallel, we explore real-system PIM implementations such as ComputeDRAM, FRaC-DRAM, PULSAR, SIMRA-DRAM, and FC-DRAM, which show that meaningful computation can be achieved on unmodified DRAM chips by leveraging simultaneous activations, reduced timing constraints, or interleaved access mechanisms. We conclude by identifying the key adoption challenges and emerging directions, including the need for programmable memory controllers, coherence models, and runtime systems that support this shift toward memory-centric computing. This survey aims to serve as both a technical reference and a roadmap for building practical, general-purpose, and scalable PIM systems.","link":"","bio":"Prof. Dr. Oğuz Ergin is a full-time Professor of Computer Engineering at the University of Sharjah (UAE) and founder of the KASIRGA Microprocessors Research Group at TOBB University of Economics & Technology (Turkey), whose RISC-V processor teams have repeatedly topped national chip-design contests. His work spans microarchitecture, fault-tolerant DRAM, and functionally complete Processing-in-Memory (PIM). Notable contributions include Turkey’s first open-source RISC-V SoC tape-out and open DRAM infrastructures such as SoftMC and PiDRAM. Oğuz’s career combines academia and industry: he was a Senior Research Scientist at Intel Barcelona Research Center (2004-05) and has held visiting appointments at University of Notre Dame, University of Edinburgh and ETH Zürich.  He published in flagship venues (ISCA, MICRO, HPCA, DSN) and served on program committees for ISCA, ICS and ICCD. Beyond research, Oğuz advises industry on low-power AI hardware and shares technology commentary with 60 k+ subscribers on YouTube. His current focus is translating PIM and DRAM-reliability insights into scalable, secure computing systems that cut the energy cost of data movement.","slide_link":""},{"time":"17:40 ~ 18:30","speaker":"Syed Mohammad Sadrossadati","topic":"Storage-Centric Computing for Modern Data-Intensive Applications","content":"Computing is bottlenecked by data. Large amounts of application data overwhelm the storage capability, communication capability, and computation capability of the modern machines we design today. As a result, many key applications' performance, efficiency, and scalability are bottlenecked by data movement. In this talk, we discuss recent research that aims to fundamentally reduce memory latency and energy and practically enable computation close to data with storage-centric computing. There are at least two promising novel directions in storage-centric computing: 1) in-flash processing, which exploits analog operational properties in flash memory chips to perform massively-parallel operations in memory with low-cost changes, 2) processing near flash memory chips, which processing takes place inside the storage controller. We show both types of architectures can enable orders of magnitude improvements in performance and energy consumption of many important workloads, such as graph analytics, database systems, machine learning, video processing, and genomics. We discuss how to enable the adoption of such fundamentally more intelligent architectures, which we believe are key to efficiency, performance, and sustainability.","link":"","bio":"Mohammad Sadrosadati is currently a senior researcher and lecturer at SAFARI Research Group, ETH Zurich, working under the supervision of Prof. Onur Mutlu. His research interests are in the areas of near-data processing, memory/storage systems, heterogeneous computing, and interconnection networks. He received the B.Sc., M.Sc., and Ph.D. degrees in Computer Engineering from Sharif University of Technology, Tehran, Iran, in 2012, 2014, and 2019, respectively. He spent one year, from April 2017 to April 2018, as an academic guest at ETH Zurich hosted by Prof. Onur Mutlu during his Ph.D. program. Due to his achievements and impact on improving the energy efficiency of GPUs, he won Khwarizmi Youth Award, one of the most prestigious awards, as the first laureate in 2020, to honor and embolden him to keep taking even bigger steps in his research career.","slide_link":""},{"time":"18:30 ~ 18:45","speaker":"Hamid Sarbazi-Azad","topic":"Closing","content":"Thank you for participating in the workshop.","link":"","bio":""}]}]`),t={text:"You can register for the workshop by clicking ",link:"https://forms.gle/14RBHvce1BbmNJ6U9"},r=[{profile:"/images/Jeong_A_Lee.jpg",name:"Jeong-A Lee",description:"Chosun University",rank:"Professor",email:"jalee@chosun.ac.kr",linkedin:""},{profile:"/images/hamid_sarbazi_azad.jpg",name:"Hamid Sarbazi-Azad",description:"Sharif University of Technology",rank:"Professor",email:`azad@{sharif.edu, ipm.ir} 
 hamid@chousn.ac.kr`,linkedin:""}],o=[{logo:"/images/KIISE.png",description:"Korean Institute of Information Scientists and Engineers (KIISE)",link:"http://m.kiise.or.kr/academyEng/main/getContent.faEng?content_no=2&MENU_ID=010200"},{logo:"/images/computer_society_of_iran.png",description:"Computer Society of Iran (CSI)",link:"https://csi.org.ir/en/"},{logo:"/images/springer.png",description:"The Journal of Supercomputing",link:"https://link.springer.com/journal/11227"}],s=["azad@sharif.edu","hamid@chosun.ac.kr","jalee@chosun.ac.kr"],c={labName:"(C) HPCAN Lab.Sharif University of Technology."};export{s as c,i as d,c as f,e as h,r as o,t as r,n as s,o as t,a as w};
